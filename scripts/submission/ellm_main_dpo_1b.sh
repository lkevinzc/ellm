# -------------------------------------- Skywork-Reward-Llama-3.1-8B
## Offline DPO
python experiment/main.py --wandb_project ellm_main_dpo_1b_40k --flash_attn --gradient_checkpointing --rnd_seed --total_gpus 5 --dap_algo DPO --reward_oracle remote --remote_rm_url http://remote-rm --pretrain cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr --beta 0.1 --prompt_data lkevinzc/tldr-with-sft-reference --input_key prompt --output_key pythia-1b-reference --sync_params_every 9999999 --max_samples 40000 --generate_max_length 53 --train_batch_size 128 --rollout_batch_size 128 --micro_rollout_batch_size 32 --micro_pi_buffer_maxlen 32 --micro_train_batch_size 8 --eval_steps 20 --use_wandb True --wandb_run_name offline
## Online DPO
python experiment/main.py --wandb_project ellm_main_dpo_1b_40k  --flash_attn --gradient_checkpointing --rnd_seed --total_gpus 5 --dap_algo DPO --reward_oracle remote --remote_rm_url http://remote-rm --pretrain cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr --beta 0.1 --prompt_data lkevinzc/tldr-with-sft-reference --input_key prompt --output_key pythia-1b-reference --sync_params_every 1 --max_samples 40000 --generate_max_length 53 --train_batch_size 128 --rollout_batch_size 128 --micro_rollout_batch_size 32 --micro_pi_buffer_maxlen 32 --micro_train_batch_size 8 --eval_steps 20  --use_wandb True --wandb_run_name online
## XPO
python experiment/run_xpo.py --wandb_project ellm_main_dpo_1b_40k  --flash_attn --gradient_checkpointing --rnd_seed --total_gpus 8 --dap_algo DPO --reward_oracle remote --remote_rm_url http://remote-rm --pretrain cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr --beta 0.1 --prompt_data lkevinzc/tldr-with-sft-reference --input_key prompt --output_key pythia-1b-reference --sync_params_every 1 --max_samples 40000 --generate_max_length 53 --train_batch_size 128 --rollout_batch_size 128 --micro_rollout_batch_size 32 --micro_pi_buffer_maxlen 32 --micro_train_batch_size 8 --eval_steps 20 --use_wandb True --wandb_run_name xpo
## APL
python experiment/run_apl.py --wandb_project ellm_main_dpo_1b_40k  --flash_attn --gradient_checkpointing --rnd_seed --total_gpus 8 --dap_algo DPO --reward_oracle remote --remote_rm_url http://remote-rm --pretrain cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr --beta 0.1 --prompt_data lkevinzc/tldr-with-sft-reference --input_key prompt --output_key pythia-1b-reference --sync_params_every 1 --num_prompt_epoch 4 --max_samples 80000 --max_step_adjustment 0.125 --generate_max_length 53 --train_batch_size 128 --rollout_batch_size 1024 --micro_rollout_batch_size 256 --micro_pi_buffer_maxlen 32 --micro_train_batch_size 8 --num_samples 8 --eval_steps 20  --use_wandb True --wandb_run_name apl
## RS
python experiment/run_rs.py --wandb_project ellm_main_dpo_1b_40k --flash_attn --gradient_checkpointing --rnd_seed --total_gpus 8 --dap_algo DPO --reward_oracle remote --remote_rm_url http://remote-rm --pretrain cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr --beta 0.1 --prompt_data lkevinzc/tldr-with-sft-reference --input_key prompt --output_key pythia-1b-reference --sync_params_every 1 --max_samples 40000 --generate_max_length 53 --train_batch_size 128 --rollout_batch_size 128 --micro_rollout_batch_size 32 --micro_pi_buffer_maxlen 32 --micro_train_batch_size 8 --eval_steps 20 --num_samples 20 --learn_rm --use_wandb True --wandb_run_name rs


## DuelingTS
python experiment/main.py --wandb_project ellm_main_dpo_1b_40k  --flash_attn --gradient_checkpointing --rnd_seed --total_gpus 8 --dap_algo DPO --reward_oracle remote --remote_rm_url http://remote-rm --pretrain cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr --beta 0.1 --prompt_data lkevinzc/tldr-with-sft-reference --input_key prompt --output_key pythia-1b-reference --sync_params_every 1 --max_samples 40000 --generate_max_length 53 --train_batch_size 128 --rollout_batch_size 128 --micro_rollout_batch_size 32 --micro_pi_buffer_maxlen 32 --micro_train_batch_size 8 --eval_steps 20 --num_samples 20 --learn_rm --exp_method EnnDuelingTS --use_wandb True --wandb_run_name dueling
